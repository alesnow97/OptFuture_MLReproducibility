---
NN_basis_dim: '32'
Policy_basis_dim: '32'
actor_lr: 0.0009665699604673259
algo_name: ONPG
base: 0
batch_size: 1000
buffer_size: 1000
debug: false
delta: 5
entropy_lambda: 0.057159323347818515
env_name: NS_Reacher
experiment: NS
extrapolator_basis: Fourier
folder_suffix: Speed4
fourier_coupled: true
fourier_k: 7
fourier_order: -1
gamma: 0.99
gauss_std: 1.5
gpu: 0
hyper: default
importance_clip: 5.0
inc: 7138
log_output: term
max_episodes: 1000
max_inner: 150
max_steps: 500
optim: rmsprop
oracle: -1
raw_basis: false
restore: false
save_count: 100
save_model: false
seed: 29
speed: 4
state_lr: 0.0013582022521035483
summary: true
swarm: false
timestamp: 5|26|18:0:33
