---
NN_basis_dim: '32'
Policy_basis_dim: '32'
actor_lr: 0.0016571651445758976
algo_name: OFPG
base: 0
batch_size: 1000
buffer_size: 1000
debug: false
delta: 3
entropy_lambda: 0.24140084170275078
env_name: NS_Reacher
experiment: NS
extrapolator_basis: Fourier
folder_suffix: Speed1
fourier_coupled: true
fourier_k: 7
fourier_order: -1
gamma: 0.99
gauss_std: 1.5
gpu: 0
hyper: default
importance_clip: 10.0
inc: 9779
log_output: term
max_episodes: 1000
max_inner: 90
max_steps: 500
optim: rmsprop
oracle: -1
raw_basis: false
restore: false
save_count: 100
save_model: false
seed: 29
speed: 1
state_lr: 0.001988346646864447
summary: true
swarm: false
timestamp: 5|25|18:0:25
