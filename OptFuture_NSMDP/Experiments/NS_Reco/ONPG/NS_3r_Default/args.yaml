---
NN_basis_dim: '32'
Policy_basis_dim: '32'
actor_lr: 0.009453953388433488
algo_name: ONPG
base: 0
batch_size: 1000
buffer_size: 1000
debug: false
delta: 5
entropy_lambda: 0.37270764366702447
env_name: NS_Reco
experiment: NS_3r_
extrapolator_basis: Fourier
folder_suffix: Default
fourier_coupled: true
fourier_k: 7
fourier_order: 3
gamma: 0.99
gauss_std: 1.5
gpu: 0
hyper: default
importance_clip: 5.0
inc: 1
log_output: term_file
max_episodes: 1000
max_inner: 150
max_steps: 500
optim: rmsprop
oracle: -1
raw_basis: true
restore: false
save_count: 100
save_model: true
seed: 29
speed: 3
state_lr: 0.001
summary: true
swarm: false
timestamp: 5|25|9:33:19
